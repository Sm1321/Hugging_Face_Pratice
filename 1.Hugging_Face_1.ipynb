{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0SI/96m/OCGUxnxOE60p5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5c2a77aedecc4a088052efab8b5bd97e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8e2c4483b934795b5c79f17f0744279","IPY_MODEL_9af4a6ee8f0c453bab5184cd796fe7ac","IPY_MODEL_6d81fc67399f45c08c24f79b35c0f0bb"],"layout":"IPY_MODEL_41448d5edc4e4ce68a9cab948d581a9e"}},"f8e2c4483b934795b5c79f17f0744279":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c342f8409744c358141a41c2bdd051b","placeholder":"​","style":"IPY_MODEL_2e89802a0ab645158dc5dbf231e30ada","value":"Loading checkpoint shards:   0%"}},"9af4a6ee8f0c453bab5184cd796fe7ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4de3c3225d4b1ab5c90a0e508e1a62","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c722e53e07be47b2b4f957cdaa92f906","value":0}},"6d81fc67399f45c08c24f79b35c0f0bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6865d2beb3f947e0aae3ec70a155c829","placeholder":"​","style":"IPY_MODEL_190f763078134c018fa5b59f89c6a6e1","value":" 0/3 [00:00&lt;?, ?it/s]"}},"41448d5edc4e4ce68a9cab948d581a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c342f8409744c358141a41c2bdd051b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e89802a0ab645158dc5dbf231e30ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4de3c3225d4b1ab5c90a0e508e1a62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c722e53e07be47b2b4f957cdaa92f906":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6865d2beb3f947e0aae3ec70a155c829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"190f763078134c018fa5b59f89c6a6e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"szuDfEt30RsV","executionInfo":{"status":"ok","timestamp":1742319056686,"user_tz":-330,"elapsed":10046,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"outputs":[],"source":["!pip install transformers -q"]},{"cell_type":"code","source":["from transformers import pipeline"],"metadata":{"id":"vr_sxA2001yq","executionInfo":{"status":"ok","timestamp":1742319093556,"user_tz":-330,"elapsed":36868,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["- distilbert/distilbert-base-uncased-finetuned-sst-2-english\n","\n","- Stanford Sentiment Treebank-2"],"metadata":{"id":"h2gDB3Qk09Ps"}},{"cell_type":"code","source":["classifier = pipeline(\"sentiment-analysis\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nD6iN3Ma03ng","executionInfo":{"status":"ok","timestamp":1742319095942,"user_tz":-330,"elapsed":2405,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"70a274cd-fa62-4551-9025-d1c9a94502de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]}]},{"cell_type":"code","source":["classifier(\"i will learn AI throughout my entire life it is like a passion\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-X9qpz506hJ","executionInfo":{"status":"ok","timestamp":1742319097004,"user_tz":-330,"elapsed":1067,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"82c935fb-0823-424e-cf4c-b5414e415645"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9987781643867493}]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["classifier(\"my friend is evil\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGov8i4i03pl","executionInfo":{"status":"ok","timestamp":1742319097033,"user_tz":-330,"elapsed":27,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"dbe65c92-7e57-4df2-9235-8789c2c80b7a"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'NEGATIVE', 'score': 0.9976063966751099}]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["classifier(\"India Won the T20 World Cup after 2007\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23Yqu61O3T_P","executionInfo":{"status":"ok","timestamp":1742319097065,"user_tz":-330,"elapsed":29,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"3d379e19-09be-46ce-f329-5217dff66eb5"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9993811845779419}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["classifier(\"I can and i will do it\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyjWRAFR3Z6b","executionInfo":{"status":"ok","timestamp":1742319097163,"user_tz":-330,"elapsed":95,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"421278ea-29ce-4e2a-aef8-1d93c5c04429"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9998464584350586}]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["generation = pipeline( \"text-generation\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5djX1Nr03sQ","executionInfo":{"status":"ok","timestamp":1742319100469,"user_tz":-330,"elapsed":3302,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"2d5a5727-6a0d-4a38-b04b-e67dd26c8793"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]}]},{"cell_type":"code","source":["generation(\"hello how are you?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pz7nK7K603vL","executionInfo":{"status":"ok","timestamp":1742319106288,"user_tz":-330,"elapsed":5816,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"f5b40620-ebfa-4ef6-aeae-355ffd43af19"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'hello how are you?\\n\\n\\nIt used to be that I always started up and did nothing until I realized that when I went to school I had to work with your program. Then I started getting into your programs at university and learning more about programs'}]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["- sshleifer/distilbart-cnn-12-6\n","\n","- repo_name/model_name"],"metadata":{"id":"cCnzlZE31opc"}},{"cell_type":"code","source":["summarizer = pipeline(\"summarization\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPJRKR5T1lpq","executionInfo":{"status":"ok","timestamp":1742319112730,"user_tz":-330,"elapsed":6439,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"5ac271ad-c8b1-4703-a3d9-04ebdeb28208"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]}]},{"cell_type":"code","source":["text = \"A large language model (LLM) is a machine learning model that uses deep learning to perform natural language processing (NLP) tasks. LLMs are trained on large amounts of text to learn how to respond to user requests with human-like language.\""],"metadata":{"id":"_6LcydZH1lsQ","executionInfo":{"status":"ok","timestamp":1742319112735,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["text=\"A large language model (LLM) is a machine learning model that uses deep learning to perform natural language processing (NLP) tasks. LLMs are trained on large amounts of text to learn how to respond to user requests with human-like language.\"\n","\n","{'summary_text': ' A large language model (LLM) is a machine learning model that uses deep learning to perform natural language processing (NLP) tasks . LLMs are trained on large amounts of text to learn how to respond to user requests with human-like language . LLM is trained on . large amounts . of text .'}]"],"metadata":{"id":"CIuCKilg1z01"}},{"cell_type":"code","source":["print(summarizer(text,max_length=10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-c_2bGG1lw9","executionInfo":{"status":"ok","timestamp":1742319115274,"user_tz":-330,"elapsed":2536,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"7b71c3a3-c506-4e81-b766-3a5a0affd8d4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Your min_length=56 must be inferior than your max_length=10.\n","/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1427: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (10). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[{'summary_text': ' A large language model (LLM'}]\n"]}]},{"cell_type":"code","source":["####\n","classifier = pipeline(\"zero-shot-classification\")\n","res = classifier(\n","    \"This is a course about Python list comprehension\",\n","    candidate_labels=[\"education\", \"politics\", \"business\"],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9AbvYNB1lzG","executionInfo":{"status":"ok","timestamp":1742319128318,"user_tz":-330,"elapsed":13045,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"b32aa2d9-c516-4367-c420-9b4772c3dd93"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]}]},{"cell_type":"code","source":["print(res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmtgcbBW1l1r","executionInfo":{"status":"ok","timestamp":1742319128370,"user_tz":-330,"elapsed":27,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"ef96cac0-c480-48f9-e82e-b9758675bfc5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["{'sequence': 'This is a course about Python list comprehension', 'labels': ['education', 'business', 'politics'], 'scores': [0.9622026681900024, 0.026841413229703903, 0.010955973528325558]}\n"]}]},{"cell_type":"code","source":["#Task:- Summarization , model:- google-bert\n","bert_summarizer = pipeline(\"summarization\",model = \"google-bert/bert-base-uncased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5ED-Q571l3x","executionInfo":{"status":"ok","timestamp":1742319129355,"user_tz":-330,"elapsed":981,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"0e8a4dd1-a104-41b7-87a8-db418054e222"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n","  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n","  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n","  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n","Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cpu\n","The model 'BertForMaskedLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"]}]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"GVsSU0cZ7-mT","executionInfo":{"status":"ok","timestamp":1742319129376,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"c49dcb92-e409-47af-d839-d8c0bd76dc88"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'A large language model (LLM) is a machine learning model that uses deep learning to perform natural language processing (NLP) tasks. LLMs are trained on large amounts of text to learn how to respond to user requests with human-like language.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["print(bert_summarizer(text,max_new_tokens=20))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ajO6jzi7-oK","executionInfo":{"status":"ok","timestamp":1742319137657,"user_tz":-330,"elapsed":8279,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"8d4f28a3-6d14-4815-e7b7-b0a8bb1db88b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'summary_text': 'a large language model ( llm ) is a machine learning model that uses deep learning to perform natural language processing ( nlp ) tasks. llms are trained on large amounts of text to learn how to respond to user requests with human - like language. a large, large, language model uses very.. large... they can handle complex complex'}]\n"]}]},{"cell_type":"markdown","source":["Use AutoModelForSequenceClassification and AutoTokenizer to load the pretrained model and it’s associated tokenizer (more on an AutoClass in the next section):\n","\n","- Bert(pre_train)--> vocab GPT(pre_traini)-->vocab\n","\n","- python-->split()\n","\n","- spacy\n","\n","- nltk\n","\n","- sent-->tokens-->embedding-->pe-->self_attention-->ff-->o/p"],"metadata":{"id":"Ci-PzrYl8E_b"}},{"cell_type":"markdown","source":["### AutoTokenizer and AutoModel"],"metadata":{"id":"NpPS9mhf9GMU"}},{"cell_type":"markdown","source":["#### AutoTokenizer\n","- A tokenizer is responsible for preprocessing text into an array of numbers as inputs to a model. There are multiple rules that govern the tokenization process, including how to split a word and at what level words should be split (learn more about tokenization in the tokenizer summary).\n","\n","- The most important thing to remember is you need to instantiate a tokenizer with the same model name to ensure you’re using the same tokenization rules a model was pretrained with."],"metadata":{"id":"f60VFuLt9wQQ"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification"],"metadata":{"id":"bNa0I6H07-p7","executionInfo":{"status":"ok","timestamp":1742319137663,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")"],"metadata":{"id":"C2cn03hj7-rp","executionInfo":{"status":"ok","timestamp":1742319138212,"user_tz":-330,"elapsed":546,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(\"google/flan-t5-large\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gMnWnAS7-tf","executionInfo":{"status":"ok","timestamp":1742319140431,"user_tz":-330,"elapsed":2202,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"3335bd57-db7e-4a31-bb8d-92f5838e0d91"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-T-XGH9w7-vo","executionInfo":{"status":"ok","timestamp":1742319140480,"user_tz":-330,"elapsed":46,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"ee8f7d7e-5516-48a3-87a1-043686617f49"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5TokenizerFast(name_or_path='google/flan-t5-large', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n","\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bl2YE8-A8N4L","executionInfo":{"status":"ok","timestamp":1742319140497,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"44946014-0e5a-4c9e-8373-8f94f71f6ac5"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForSequenceClassification(\n","  (transformer): T5Model(\n","    (shared): Embedding(32128, 1024)\n","    (encoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 1024)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","                (relative_attention_bias): Embedding(32, 16)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1-23): 23 x T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (decoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 1024)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","                (relative_attention_bias): Embedding(32, 16)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1-23): 23 x T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=1024, out_features=1024, bias=False)\n","                (k): Linear(in_features=1024, out_features=1024, bias=False)\n","                (v): Linear(in_features=1024, out_features=1024, bias=False)\n","                (o): Linear(in_features=1024, out_features=1024, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n","                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (classification_head): T5ClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.0, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["#save the directory\n","save_directory=\"my_model_dir\""],"metadata":{"id":"FVxIlMsp8N5u","executionInfo":{"status":"ok","timestamp":1742319140502,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained(save_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RscbcqXu8N9-","executionInfo":{"status":"ok","timestamp":1742319140521,"user_tz":-330,"elapsed":20,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"a69c8e58-30ef-428f-be26-c47ae21469d6"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('my_model_dir/tokenizer_config.json',\n"," 'my_model_dir/special_tokens_map.json',\n"," 'my_model_dir/spiece.model',\n"," 'my_model_dir/added_tokens.json',\n"," 'my_model_dir/tokenizer.json')"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer,device=0)\n","\n","res = classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n","\n","print(res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nJy9zyN8OCa","executionInfo":{"status":"ok","timestamp":1742319152735,"user_tz":-330,"elapsed":12213,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}},"outputId":"60f65345-649b-4910-88bd-aa3e6dd10281"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["[{'label': 'LABEL_1', 'score': 0.579962968826294}]\n"]}]},{"cell_type":"markdown","source":["| Class                                      | Task                                        | Example Use Case                                      | Example Model                                      |\n","| :----------------------------------------- | :------------------------------------------ | :--------------------------------------------------- | :------------------------------------------------ |\n","| **🔹 Tokenization Classes**                 |                                            |                                                      |                                                   |\n","| `AutoTokenizer`                            | Tokenizes text for model input              | Converts sentences into token IDs                    | `bert-base-uncased`                               |\n","| `PreTrainedTokenizerFast`                  | Faster tokenizer                            | Supports tokenization with Rust-backed libraries     | `roberta-base`                                    |\n","| **🔹 General Model Loading**                |                                            |                                                      |                                                   |\n","| `AutoModel`                                | General-purpose model (hidden states)       | Feature extraction, embeddings                       | `bert-base-uncased`                               |\n","| **🔹 Text-Based Tasks**                     |                                            |                                                      |                                                   |\n","| `AutoModelForSequenceClassification`       | Text classification                         | Sentiment analysis, spam detection                   | `distilbert-base-uncased-finetuned-sst-2-english` |\n","| `AutoModelForTokenClassification`          | Named Entity Recognition (NER)              | Extracts entities (e.g., names, locations)          | `dbmdz/bert-large-cased-finetuned-conll03-english` |\n","| `AutoModelForQuestionAnswering`            | Question Answering (QA)                     | Answering questions from a given passage             | `deepset/roberta-base-squad2`                     |\n","| `AutoModelForSeq2SeqLM`                    | Text Generation                             | Summarization, translation (e.g., T5, BART)         | `facebook/bart-large-cnn`                         |\n","| `AutoModelForMaskedLM`                     | Fill-in-the-blank predictions               | Masked Language Modeling (MLM), like BERT           | `bert-base-uncased`                               |\n","| `AutoModelForCausalLM`                     | Autoregressive Text Generation              | GPT-like models (e.g., GPT-2, Llama)                 | `gpt2`                                            |\n","| `AutoModelForMultipleChoice`               | Multiple-choice classification              | AI answering multiple-choice questions              | `roberta-large-mnli`                              |\n","| `AutoModelForNextSentencePrediction`       | Predicts if two sentences are consecutive   | Used in BERT-style models                           | `bert-base-uncased`                               |\n","| **🔹 Speech & Audio Processing**            |                                            |                                                      |                                                   |\n","| `AutoModelForSpeechSeq2Seq`                | Speech-to-text                              | Automatic Speech Recognition (ASR)                   | `openai/whisper-small`                            |\n","| `AutoModelForCTC`                          | Speech-to-text with CTC loss                | Audio transcription (e.g., Wav2Vec2)                 | `facebook/wav2vec2-large-960h`                    |\n","| `AutoProcessor`                            | Processes audio inputs                      | Used with speech models for preprocessing           | `facebook/wav2vec2-large-xlsr-53`                 |\n","| **🔹 Vision (Image Processing)**            |                                            |                                                      |                                                   |\n","| `AutoModelForImageClassification`          | Image classification                        | Object detection, image labeling                    | `google/vit-base-patch16-224`                     |\n","| `AutoFeatureExtractor`                     | Extracts features from images               | Used with vision models for preprocessing           | `facebook/detectron2`                             |\n","| **🔹 Multimodal (Text + Image)**            |                                            |                                                      |                                                   |\n","| `AutoModelForVision2Seq`                   | Image captioning                            | Generates descriptions for images                   | `nlpconnect/vit-gpt2-image-captioning`           |\n","| `AutoModelForZeroShotImageClassification`  | Classifies images without fine-tuning       | Zero-shot learning (e.g., CLIP)                     | `openai/clip-vit-base-patch32`                    |\n"],"metadata":{"id":"X1B_7C-0O6CC"}},{"cell_type":"code","source":["### Auto Model fpr Generation Model\n","from transformers import AutoTokenizer,AutoModelForCausalLM\n","\n","model_name = \"gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n"],"metadata":{"id":"p3DLaSfPDB2r","executionInfo":{"status":"ok","timestamp":1742319155491,"user_tz":-330,"elapsed":2752,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["### Auto Model for Generation Model\n","### Mistral Instruct\n","from transformers import AutoTokenizer,AutoModelForCausalLM\n","model_name = \"mistralai/Mistral-7B-Instruct-v0.2\""],"metadata":{"id":"76jtSQk-RTPx","executionInfo":{"status":"ok","timestamp":1742318995413,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"id":"KGM9FxV2QAb-","executionInfo":{"status":"ok","timestamp":1742318995641,"user_tz":-330,"elapsed":215,"user":{"displayName":"Mohan DS","userId":"05181729263002066506"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5c2a77aedecc4a088052efab8b5bd97e","f8e2c4483b934795b5c79f17f0744279","9af4a6ee8f0c453bab5184cd796fe7ac","6d81fc67399f45c08c24f79b35c0f0bb","41448d5edc4e4ce68a9cab948d581a9e","4c342f8409744c358141a41c2bdd051b","2e89802a0ab645158dc5dbf231e30ada","0d4de3c3225d4b1ab5c90a0e508e1a62","c722e53e07be47b2b4f957cdaa92f906","6865d2beb3f947e0aae3ec70a155c829","190f763078134c018fa5b59f89c6a6e1"]},"id":"GbOYAqcYQ7-P","outputId":"3bdf3a6b-24ea-410a-cd49-c7250bfbdc94"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c2a77aedecc4a088052efab8b5bd97e"}},"metadata":{}}]},{"cell_type":"code","source":["model"],"metadata":{"id":"OFKo0M8KQ8AU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L8RHaXZ1Q8EK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"764cbNmYReL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7H4cEDLKRePD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"f1PmXusAReTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LAFJXRsRReV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qWLldDk-Q8Gb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. huggingface use via langchain\n","2. finetune llm or lm model using hf - - transformer\n","3. TRL\n","4. text-->audio/text-->image"],"metadata":{"id":"cVkCt1MhDCDa"}},{"cell_type":"code","source":["!pip install langchain-huggingface -q"],"metadata":{"id":"Oog0sNdKDLIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequence = \"Using a Transformer network is simple\"\n","\n","res = tokenizer(sequence)\n","print(res)\n","\n","tokens = tokenizer.tokenize(sequence)\n","print(tokens)\n","\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","print(ids)\n","\n","decoded_string = tokenizer.decode(ids)\n","print(decoded_string)"],"metadata":{"id":"gLeSSWquDMNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t28GPqgeHzgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lNdK6MzpHzkh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oTGyrBfvHznE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hRD7YbAgDQQ-"},"execution_count":null,"outputs":[]}]}